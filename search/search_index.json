{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview K8up is a backup operator that will handle PVC and app backups on a k8s/OpenShift cluster. Just create a schedule object in the namespace you\u2019d like to backup. It\u2019s that easy. K8up takes care of the rest. It also provides a Prometheus endpoint for monitoring. K8up is currently under heavy development and far from feature complete. But it should already be stable enough for production use.","title":"Home"},{"location":"#overview","text":"K8up is a backup operator that will handle PVC and app backups on a k8s/OpenShift cluster. Just create a schedule object in the namespace you\u2019d like to backup. It\u2019s that easy. K8up takes care of the rest. It also provides a Prometheus endpoint for monitoring. K8up is currently under heavy development and far from feature complete. But it should already be stable enough for production use.","title":"Overview"},{"location":"advanced-config/","text":"Advanced config The operator has two ways for configuration: Per namespace backups. Optimal for shared clusters Global settings with namespaced schedules. Optimal for private clusters Environment variables BACKUP_IMAGE URL for the restic image, default: 172.30.1.1:5000/myproject/restic BACKUP_ANNOTATION the annotation to be used for filtering, default: appuio.ch/backup BACKUP_CHECKSCHEDULE the default check schedule, default: 0 0 * * 0 BACKUP_PODFILTER the filter used to find the backup pods, default: backupPod=true BACKUP_DATAPATH where the PVCs should get mounted in the container, default /data BACKUP_JOBNAME names for the backup job objects in OpenShift, default: backupjob BACKUP_PODNAME names for the backup pod objects in OpenShift, default: backupjob-pod BACKUP_RESTARTPOLICY set the RestartPolicy for the backup jobs. According to the docs this should be OnFailure for jobs that terminate, default: OnFailure BACKUP_METRICBIND set the bind address for the prometheus endpoint, default: :8080 BACKUP_PROMURL set the operator wide default prometheus push gateway, default http://127.0.0.1/ BACKUP_BACKUPCOMMANDANNOTATION set the annotation name where the backup commands are stored, default appuio.ch/backupcommand BACKUP_PODEXECROLENAME set the rolename that should be used for pod command execution, default pod-executor BACKUP_PODEXECACCOUNTNAME set the service account name that should be used for the pod command execution, default: pod-executor BACKUP_GLOBALACCESSKEYID set the S3 access key id to be used globaly BACKUP_GLOBALSECRETACCESSKEY set the S3 secret access key to be used globaly BACKUP_GLOBALREPOPASSWORD set the restic repository password to be used globaly BACKUP_GLOBALKEEPJOBS set the count of jobs to keep globally BACKUP_GLOBALS3ENDPOINT set the S3 endpoint to be used globally BACKUP_GLOBALS3BUCKET set the S3 bucket to be used globally BACKUP_GLOBALSTATSURL set the URL for wrestic to post additional metrics gloablly, default \"\" BACKUP_GLOBALRESTORES3BUCKET set the global restore S3 bucket for restores BACKUP_GLOBALRESTORES3ENDPOINT set the global restore S3 endpoint for the restores (needs the scheme [http/https] BACKUP_GLOBALRESTORES3ACCESKEYID set the global resotre S3 accessKeyID for restores BACKUP_GLOBALRESTORES3SECRETACCESSKEY set the global restore S3 SecretAccessKey for restores You only need to adjust BACKUP_IMAGE everything else can be left default. Global settings Each variable starting with BACKUP_GLOBAL* is used to configure a global default for all namespaces. F.e. if you configure the S3 bucket and credentials you won't have to specify them in the schedule or backup CRDs. Note It is possible to overwrite the global settings. Simply set the specific configuration in the CRD and it will use that instead. Manual Installation All required definitions for the installation are located at manifest/install/ : kubectl apply -f manifest/install/ Please be aware that these manifests are intended for dev and as examples. They are not the official way to install the operator in production. For this we provide a helm chart at https://github.com/appuio/charts. You may need to adjust the namespaces in the manifests. There are various other examples under manifest/examples/ .","title":"Advanced Configuration"},{"location":"advanced-config/#advanced-config","text":"The operator has two ways for configuration: Per namespace backups. Optimal for shared clusters Global settings with namespaced schedules. Optimal for private clusters","title":"Advanced config"},{"location":"advanced-config/#environment-variables","text":"BACKUP_IMAGE URL for the restic image, default: 172.30.1.1:5000/myproject/restic BACKUP_ANNOTATION the annotation to be used for filtering, default: appuio.ch/backup BACKUP_CHECKSCHEDULE the default check schedule, default: 0 0 * * 0 BACKUP_PODFILTER the filter used to find the backup pods, default: backupPod=true BACKUP_DATAPATH where the PVCs should get mounted in the container, default /data BACKUP_JOBNAME names for the backup job objects in OpenShift, default: backupjob BACKUP_PODNAME names for the backup pod objects in OpenShift, default: backupjob-pod BACKUP_RESTARTPOLICY set the RestartPolicy for the backup jobs. According to the docs this should be OnFailure for jobs that terminate, default: OnFailure BACKUP_METRICBIND set the bind address for the prometheus endpoint, default: :8080 BACKUP_PROMURL set the operator wide default prometheus push gateway, default http://127.0.0.1/ BACKUP_BACKUPCOMMANDANNOTATION set the annotation name where the backup commands are stored, default appuio.ch/backupcommand BACKUP_PODEXECROLENAME set the rolename that should be used for pod command execution, default pod-executor BACKUP_PODEXECACCOUNTNAME set the service account name that should be used for the pod command execution, default: pod-executor BACKUP_GLOBALACCESSKEYID set the S3 access key id to be used globaly BACKUP_GLOBALSECRETACCESSKEY set the S3 secret access key to be used globaly BACKUP_GLOBALREPOPASSWORD set the restic repository password to be used globaly BACKUP_GLOBALKEEPJOBS set the count of jobs to keep globally BACKUP_GLOBALS3ENDPOINT set the S3 endpoint to be used globally BACKUP_GLOBALS3BUCKET set the S3 bucket to be used globally BACKUP_GLOBALSTATSURL set the URL for wrestic to post additional metrics gloablly, default \"\" BACKUP_GLOBALRESTORES3BUCKET set the global restore S3 bucket for restores BACKUP_GLOBALRESTORES3ENDPOINT set the global restore S3 endpoint for the restores (needs the scheme [http/https] BACKUP_GLOBALRESTORES3ACCESKEYID set the global resotre S3 accessKeyID for restores BACKUP_GLOBALRESTORES3SECRETACCESSKEY set the global restore S3 SecretAccessKey for restores You only need to adjust BACKUP_IMAGE everything else can be left default.","title":"Environment variables"},{"location":"advanced-config/#global-settings","text":"Each variable starting with BACKUP_GLOBAL* is used to configure a global default for all namespaces. F.e. if you configure the S3 bucket and credentials you won't have to specify them in the schedule or backup CRDs. Note It is possible to overwrite the global settings. Simply set the specific configuration in the CRD and it will use that instead.","title":"Global settings"},{"location":"advanced-config/#manual-installation","text":"All required definitions for the installation are located at manifest/install/ : kubectl apply -f manifest/install/ Please be aware that these manifests are intended for dev and as examples. They are not the official way to install the operator in production. For this we provide a helm chart at https://github.com/appuio/charts. You may need to adjust the namespaces in the manifests. There are various other examples under manifest/examples/ .","title":"Manual Installation"},{"location":"getting-started/","text":"Getting Started Getting Started Prerequisites Install K8up Install MinIO Create a PersistentVolumenClaim Resource Create Backup Credentials Set Up a Backup Schedule Checking the Status of Backup Jobs Application-Aware Backups What is Next? This document provides a quick introduction to K8up, how it works and how to use it. Prerequisites This section provides information about the minimum requirements for testing K8up on Minikube. Before starting please make sure Minikube is installed and started, and that helm is installed and properly initialized in your Minikube. Install K8up The most convenient way to install K8up is with helm . First add the appuio repository: helm repo add appuio https://charts.appuio.ch helm repo update Then install K8up itself: helm install appuio/k8up Install MinIO MinIO is a distributed object storage service for high performance, high scale data infrastructures. It is a drop in replacement for AWS S3 in your own environment. We are going to install it to simulate a remote S3 bucket where our backups are going to be stored: kubectl create -f https://github.com/minio/minio/blob/master/docs/orchestration/kubernetes/minio-standalone-pvc.yaml?raw=true kubectl create -f https://github.com/minio/minio/blob/master/docs/orchestration/kubernetes/minio-standalone-deployment.yaml?raw=true kubectl create -f https://github.com/minio/minio/blob/master/docs/orchestration/kubernetes/minio-standalone-service.yaml?raw=true After a few minutes you should be able to see your MinIO installation on the browser using minikube service minio-service . The default Minio installation uses the access key minio and secret key minio123 . Create a PersistentVolumenClaim Resource This will be the resource backed up by K8up: kind: PersistentVolumeClaim apiVersion: v1 metadata: name: apvc spec: accessModes: - ReadWriteMany resources: requests: storage: 1Gi Save the YAML above in a file named pvc.yml and use the kubectl apply -f pvc.yml command to deploy this configuration to your cluster. Create Backup Credentials Create the secret credentials for the backup repository: apiVersion: v1 kind: Secret metadata: name: backup-credentials namespace: default type: Opaque data: username: bWluaW8= password: bWluaW8xMjM= --- apiVersion: v1 kind: Secret metadata: name: backup-repo namespace: default type: Opaque data: password: cEBzc3cwcmQ= Save the YAML above in a file named secrets.yml and use the kubectl apply -f secrets.yml command to deploy this configuration to your cluster. The values of the secrets need to be encoded in Base64 encoding. The default MinIO installation uses the access key minio and secret key minio123 , which are encoded as Base64 in the backup-credentials Secret definition. You can easily convert a string to Base64 format in a terminal session as follows: echo -n \"p@ssw0rd\" | base64 Warning Please store that password somewhere safe. This is the encryption password for Restic. Without it you will lose access to the backup permanently. Set Up a Backup Schedule The custom Schedule object below defines the frequency, destination and secrets required to backup items in your namespace: apiVersion: backup.appuio.ch/v1alpha1 kind: Schedule metadata: name: schedule-test spec: backend: s3: endpoint: http://minio-service:9000 bucket: backups accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password repoPasswordSecretRef: name: backup-repo key: password archive: schedule: '0 0 1 * *' restoreMethod: s3: endpoint: http://minio-service:9000 bucket: archive accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password backup: schedule: '*/5 * * * *' keepJobs: 4 promURL: http://minio-service:9000 check: schedule: '0 1 * * 1' promURL: http://minio-service:9000 prune: schedule: '0 1 * * 0' retention: keepLast: 5 keepDaily: 14 Save the YAML above in a file named backup.yml and use the kubectl apply -f backup.yml command to deploy this configuration to your cluster. The file above will instruct the operator to do backups every 5 minutes, as well as monthly prune and check jobs for repository maintenance. It will also archive the latest snapshots to the archive bucket once each week. After 5 minutes of running this demo, you should be able to run the command minikube service minio-service and see the backups in a backups bucket inside the web administration. Remember that the default access and secret keys are minio and minio123 respectively. Feel free to adjust the frequencies to your liking. To help you with the crontab syntax, we recommend to check crontab.guru . Note You can always check the state and configuration of your backup by using kubectl describe schedule By default all PVCs are stored in backup. By adding the annotation appuio.ch/backup=false to a PVC object it will get excluded from backup. Checking the Status of Backup Jobs Every time a job starts, it creates a separate pod in your namespace. You can see them using kubectl pods . You can then use the usual kubectl logs <POD NAME> command to troubleshoot a failed backup job. Application-Aware Backups It is possible to define annotations on pods with backup commands. These backup commands should create an application-aware backup and stream it to stdout. Define an annotation on pod: <SNIP> template: metadata: labels: app: mariadb annotations: appuio.ch/backupcommand: mysqldump -uroot -psecure --all-databases <SNIP> With this annotation the operator will trigger that command inside the the container and capture the stdout to a backup. Tested with: MariaDB MongoDB tar to stdout But it should work with any command that has the ability to output the backup to stdout. What is Next? For advanced configuration of the operator please see Advanced config .","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"Getting Started Prerequisites Install K8up Install MinIO Create a PersistentVolumenClaim Resource Create Backup Credentials Set Up a Backup Schedule Checking the Status of Backup Jobs Application-Aware Backups What is Next? This document provides a quick introduction to K8up, how it works and how to use it.","title":"Getting Started"},{"location":"getting-started/#prerequisites","text":"This section provides information about the minimum requirements for testing K8up on Minikube. Before starting please make sure Minikube is installed and started, and that helm is installed and properly initialized in your Minikube.","title":"Prerequisites"},{"location":"getting-started/#install-k8up","text":"The most convenient way to install K8up is with helm . First add the appuio repository: helm repo add appuio https://charts.appuio.ch helm repo update Then install K8up itself: helm install appuio/k8up","title":"Install K8up"},{"location":"getting-started/#install-minio","text":"MinIO is a distributed object storage service for high performance, high scale data infrastructures. It is a drop in replacement for AWS S3 in your own environment. We are going to install it to simulate a remote S3 bucket where our backups are going to be stored: kubectl create -f https://github.com/minio/minio/blob/master/docs/orchestration/kubernetes/minio-standalone-pvc.yaml?raw=true kubectl create -f https://github.com/minio/minio/blob/master/docs/orchestration/kubernetes/minio-standalone-deployment.yaml?raw=true kubectl create -f https://github.com/minio/minio/blob/master/docs/orchestration/kubernetes/minio-standalone-service.yaml?raw=true After a few minutes you should be able to see your MinIO installation on the browser using minikube service minio-service . The default Minio installation uses the access key minio and secret key minio123 .","title":"Install MinIO"},{"location":"getting-started/#create-a-persistentvolumenclaim-resource","text":"This will be the resource backed up by K8up: kind: PersistentVolumeClaim apiVersion: v1 metadata: name: apvc spec: accessModes: - ReadWriteMany resources: requests: storage: 1Gi Save the YAML above in a file named pvc.yml and use the kubectl apply -f pvc.yml command to deploy this configuration to your cluster.","title":"Create a PersistentVolumenClaim Resource"},{"location":"getting-started/#create-backup-credentials","text":"Create the secret credentials for the backup repository: apiVersion: v1 kind: Secret metadata: name: backup-credentials namespace: default type: Opaque data: username: bWluaW8= password: bWluaW8xMjM= --- apiVersion: v1 kind: Secret metadata: name: backup-repo namespace: default type: Opaque data: password: cEBzc3cwcmQ= Save the YAML above in a file named secrets.yml and use the kubectl apply -f secrets.yml command to deploy this configuration to your cluster. The values of the secrets need to be encoded in Base64 encoding. The default MinIO installation uses the access key minio and secret key minio123 , which are encoded as Base64 in the backup-credentials Secret definition. You can easily convert a string to Base64 format in a terminal session as follows: echo -n \"p@ssw0rd\" | base64 Warning Please store that password somewhere safe. This is the encryption password for Restic. Without it you will lose access to the backup permanently.","title":"Create Backup Credentials"},{"location":"getting-started/#set-up-a-backup-schedule","text":"The custom Schedule object below defines the frequency, destination and secrets required to backup items in your namespace: apiVersion: backup.appuio.ch/v1alpha1 kind: Schedule metadata: name: schedule-test spec: backend: s3: endpoint: http://minio-service:9000 bucket: backups accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password repoPasswordSecretRef: name: backup-repo key: password archive: schedule: '0 0 1 * *' restoreMethod: s3: endpoint: http://minio-service:9000 bucket: archive accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password backup: schedule: '*/5 * * * *' keepJobs: 4 promURL: http://minio-service:9000 check: schedule: '0 1 * * 1' promURL: http://minio-service:9000 prune: schedule: '0 1 * * 0' retention: keepLast: 5 keepDaily: 14 Save the YAML above in a file named backup.yml and use the kubectl apply -f backup.yml command to deploy this configuration to your cluster. The file above will instruct the operator to do backups every 5 minutes, as well as monthly prune and check jobs for repository maintenance. It will also archive the latest snapshots to the archive bucket once each week. After 5 minutes of running this demo, you should be able to run the command minikube service minio-service and see the backups in a backups bucket inside the web administration. Remember that the default access and secret keys are minio and minio123 respectively. Feel free to adjust the frequencies to your liking. To help you with the crontab syntax, we recommend to check crontab.guru . Note You can always check the state and configuration of your backup by using kubectl describe schedule By default all PVCs are stored in backup. By adding the annotation appuio.ch/backup=false to a PVC object it will get excluded from backup.","title":"Set Up a Backup Schedule"},{"location":"getting-started/#checking-the-status-of-backup-jobs","text":"Every time a job starts, it creates a separate pod in your namespace. You can see them using kubectl pods . You can then use the usual kubectl logs <POD NAME> command to troubleshoot a failed backup job.","title":"Checking the Status of Backup Jobs"},{"location":"getting-started/#application-aware-backups","text":"It is possible to define annotations on pods with backup commands. These backup commands should create an application-aware backup and stream it to stdout. Define an annotation on pod: <SNIP> template: metadata: labels: app: mariadb annotations: appuio.ch/backupcommand: mysqldump -uroot -psecure --all-databases <SNIP> With this annotation the operator will trigger that command inside the the container and capture the stdout to a backup. Tested with: MariaDB MongoDB tar to stdout But it should work with any command that has the ability to output the backup to stdout.","title":"Application-Aware Backups"},{"location":"getting-started/#what-is-next","text":"For advanced configuration of the operator please see Advanced config .","title":"What is Next?"},{"location":"object-specifications/","text":"Object Specifications The K8up operator includes various CRDs which get added to the cluster. Here We'll explain them in more detail. Schedule With the schedule CRD it is possible to put all other CRDs on a schedule. apiVersion: backup.appuio.ch/v1alpha1 kind: Schedule metadata: name: schedule-test spec: backend: s3: endpoint: http://10.144.1.224:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password repoPasswordSecretRef: name: backup-repo key: password archive: schedule: '0 * * * *' restoreMethod: s3: endpoint: http://10.144.1.224:9000 bucket: restoremini accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password backup: schedule: '* * * * *' keepJobs: 4 promURL: http://10.144.1.224:9000 check: schedule: '*/5 * * * *' promURL: http://10.144.1.224:9000 prune: schedule: '*/2 * * * *' retention: keepLast: 5 keepDaily: 14 Settings archive : see archive for further explaination backend : see backend for further explanaition check : see check for further explanaition prune : see prune for further explanaition Restore It's now possible to define various restore jobs. Currently these kinds of restores are supported: To a PVC To S3 as tar.gz Example for a restore to a PVC: apiVersion: backup.appuio.ch/v1alpha1 kind: Restore metadata: name: restore-test spec: repoPasswordSecretRef: name: backup-repo key: password restoreMethod: folder: claimName: restore backend: s3: endpoint: http://10.144.1.224:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password This will restore the latest snapshot from http://10.144.1.224:9000 to the PVC with the name restore . Settings TODO: Archive The archive CRD will take the latest snapshots from each namespace/project in the repository. Thus you should only run one schedule per repository for archival as there's a chance that you'll archive snapshots more than once. apiVersion: backup.appuio.ch/v1alpha1 kind: Archive metadata: name: archive-test spec: repoPasswordSecretRef: name: backup-repo key: password restoreMethod: s3: endpoint: http://10.144.1.224:9000 bucket: restoremini accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password backend: s3: endpoint: http://10.144.1.224:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password Settings TODO: Backup This will trigger a single backup. apiVersion: backup.appuio.ch/v1alpha1 kind: Backup metadata: name: baas-test spec: keepJobs: 4 backend: s3: endpoint: http://10.144.1.224:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password retention: keepLast: 5 keepDaily: 14 promURL: http://10.144.1.224:9000 repoPasswordSecretRef: name: backup-repo key: password Settings TODO: Check This will trigger a single check run on the repository. apiVersion: backup.appuio.ch/v1alpha1 kind: Check metadata: name: check-test spec: backend: s3: endpoint: http://10.144.1.224:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password promURL: http://10.144.1.224:9000 repoPasswordSecretRef: name: backup-repo key: password Settings TODO: Prune This will trigger a single prune run and delete the snapshots according to the defined retention rules. This one needs to run exclusively on the repository. No other jobs must run on the same repository while this one is still running. The operator ensures that the prune will run exclusively on the repository. apiVersion: backup.appuio.ch/v1alpha1 kind: Prune metadata: name: prune-test spec: retention: keepLast: 5 keepDaily: 14 backend: s3: endpoint: http://10.144.1.224:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password repoPasswordSecretRef: name: backup-repo key: password promURL: http://10.144.1.224:9000 Settings TODO: Backend TODO: Settings TODO:","title":"Object Specifications"},{"location":"object-specifications/#object-specifications","text":"The K8up operator includes various CRDs which get added to the cluster. Here We'll explain them in more detail.","title":"Object Specifications"},{"location":"object-specifications/#schedule","text":"With the schedule CRD it is possible to put all other CRDs on a schedule. apiVersion: backup.appuio.ch/v1alpha1 kind: Schedule metadata: name: schedule-test spec: backend: s3: endpoint: http://10.144.1.224:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password repoPasswordSecretRef: name: backup-repo key: password archive: schedule: '0 * * * *' restoreMethod: s3: endpoint: http://10.144.1.224:9000 bucket: restoremini accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password backup: schedule: '* * * * *' keepJobs: 4 promURL: http://10.144.1.224:9000 check: schedule: '*/5 * * * *' promURL: http://10.144.1.224:9000 prune: schedule: '*/2 * * * *' retention: keepLast: 5 keepDaily: 14","title":"Schedule"},{"location":"object-specifications/#settings","text":"archive : see archive for further explaination backend : see backend for further explanaition check : see check for further explanaition prune : see prune for further explanaition","title":"Settings"},{"location":"object-specifications/#restore","text":"It's now possible to define various restore jobs. Currently these kinds of restores are supported: To a PVC To S3 as tar.gz Example for a restore to a PVC: apiVersion: backup.appuio.ch/v1alpha1 kind: Restore metadata: name: restore-test spec: repoPasswordSecretRef: name: backup-repo key: password restoreMethod: folder: claimName: restore backend: s3: endpoint: http://10.144.1.224:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password This will restore the latest snapshot from http://10.144.1.224:9000 to the PVC with the name restore .","title":"Restore"},{"location":"object-specifications/#settings_1","text":"TODO:","title":"Settings"},{"location":"object-specifications/#archive","text":"The archive CRD will take the latest snapshots from each namespace/project in the repository. Thus you should only run one schedule per repository for archival as there's a chance that you'll archive snapshots more than once. apiVersion: backup.appuio.ch/v1alpha1 kind: Archive metadata: name: archive-test spec: repoPasswordSecretRef: name: backup-repo key: password restoreMethod: s3: endpoint: http://10.144.1.224:9000 bucket: restoremini accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password backend: s3: endpoint: http://10.144.1.224:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password","title":"Archive"},{"location":"object-specifications/#settings_2","text":"TODO:","title":"Settings"},{"location":"object-specifications/#backup","text":"This will trigger a single backup. apiVersion: backup.appuio.ch/v1alpha1 kind: Backup metadata: name: baas-test spec: keepJobs: 4 backend: s3: endpoint: http://10.144.1.224:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password retention: keepLast: 5 keepDaily: 14 promURL: http://10.144.1.224:9000 repoPasswordSecretRef: name: backup-repo key: password","title":"Backup"},{"location":"object-specifications/#settings_3","text":"TODO:","title":"Settings"},{"location":"object-specifications/#check","text":"This will trigger a single check run on the repository. apiVersion: backup.appuio.ch/v1alpha1 kind: Check metadata: name: check-test spec: backend: s3: endpoint: http://10.144.1.224:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password promURL: http://10.144.1.224:9000 repoPasswordSecretRef: name: backup-repo key: password","title":"Check"},{"location":"object-specifications/#settings_4","text":"TODO:","title":"Settings"},{"location":"object-specifications/#prune","text":"This will trigger a single prune run and delete the snapshots according to the defined retention rules. This one needs to run exclusively on the repository. No other jobs must run on the same repository while this one is still running. The operator ensures that the prune will run exclusively on the repository. apiVersion: backup.appuio.ch/v1alpha1 kind: Prune metadata: name: prune-test spec: retention: keepLast: 5 keepDaily: 14 backend: s3: endpoint: http://10.144.1.224:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password repoPasswordSecretRef: name: backup-repo key: password promURL: http://10.144.1.224:9000","title":"Prune"},{"location":"object-specifications/#settings_5","text":"TODO:","title":"Settings"},{"location":"object-specifications/#backend","text":"TODO:","title":"Backend"},{"location":"object-specifications/#settings_6","text":"TODO:","title":"Settings"},{"location":"restore/","text":"Restore It is possible to tell the operator to perform restores either to a PVC or an S3 bucket. For this you can create a restore object: apiVersion: backup.appuio.ch/v1alpha1 kind: Restore metadata: name: restore-test spec: repoPasswordSecretRef: name: backup-repo key: password s3: endpoint: http://localhost:9000 bucket: restore accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password backend: s3: endpoint: http://localhost:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password This will trigger a one time job to restore the latest snapshot to S3. Manual restore via Restic To manually restore you'll need: * Linux machine with restic * Fuse (Optional for mounting) Let's take this backend example from a schedule: backend: s3: endpoint: http://localhost:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password You'll need the credentials from the secrets as well as the encryption key. With that information you can configure restic: export RESTIC_REPOSITORY=s3:http://localhost/baas export RESTIC_PASSWORD=p@assword export AWS_ACCESS_KEY_ID=8U0UDNYPNUDTUS1LIAF3 export AWS_SECRET_ACCESS_KEY=ip3cdrkXcHmH4S7if7erKPNoxDn27V0vrg6CHHem Now you can use Restic to browse and restore snapshots: # List snapshots restic snapshots repository dec6d66c opened successfully, password is correct ID Date Host Tags Directory ---------------------------------------------------------------------- 5ed64a2d 2018-06-08 09:18:34 macbook-vshn.local /data ---------------------------------------------------------------------- 1 snapshots restic restore 5ed64a2d --target /restore # Or mount the repository for convenient restores restic mount ~/Desktop/mount repository dec6d66c opened successfully, password is correct Now serving the repository at /Users/simonbeck/Desktop/mount/ Dont forget to umount after quitting! ll ~/Desktop/mount total 0 dr-xr-xr-x 1 simonbeck staff 0 Jun 8 09:21 . drwx------+ 6 simonbeck staff 192 Jun 8 09:15 .. dr-xr-xr-x 1 simonbeck staff 0 Jun 8 09:21 hosts dr-xr-xr-x 1 simonbeck staff 0 Jun 8 09:21 ids dr-xr-xr-x 1 simonbeck staff 0 Jun 8 09:21 snapshots dr-xr-xr-x 1 simonbeck staff 0 Jun 8 09:21 tags Here you can browse all backups by host, ids, snapshots or tags.","title":"Restore"},{"location":"restore/#restore","text":"It is possible to tell the operator to perform restores either to a PVC or an S3 bucket. For this you can create a restore object: apiVersion: backup.appuio.ch/v1alpha1 kind: Restore metadata: name: restore-test spec: repoPasswordSecretRef: name: backup-repo key: password s3: endpoint: http://localhost:9000 bucket: restore accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password backend: s3: endpoint: http://localhost:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password This will trigger a one time job to restore the latest snapshot to S3.","title":"Restore"},{"location":"restore/#manual-restore-via-restic","text":"To manually restore you'll need: * Linux machine with restic * Fuse (Optional for mounting) Let's take this backend example from a schedule: backend: s3: endpoint: http://localhost:9000 bucket: baas accessKeyIDSecretRef: name: backup-credentials key: username secretAccessKeySecretRef: name: backup-credentials key: password You'll need the credentials from the secrets as well as the encryption key. With that information you can configure restic: export RESTIC_REPOSITORY=s3:http://localhost/baas export RESTIC_PASSWORD=p@assword export AWS_ACCESS_KEY_ID=8U0UDNYPNUDTUS1LIAF3 export AWS_SECRET_ACCESS_KEY=ip3cdrkXcHmH4S7if7erKPNoxDn27V0vrg6CHHem Now you can use Restic to browse and restore snapshots: # List snapshots restic snapshots repository dec6d66c opened successfully, password is correct ID Date Host Tags Directory ---------------------------------------------------------------------- 5ed64a2d 2018-06-08 09:18:34 macbook-vshn.local /data ---------------------------------------------------------------------- 1 snapshots restic restore 5ed64a2d --target /restore # Or mount the repository for convenient restores restic mount ~/Desktop/mount repository dec6d66c opened successfully, password is correct Now serving the repository at /Users/simonbeck/Desktop/mount/ Dont forget to umount after quitting! ll ~/Desktop/mount total 0 dr-xr-xr-x 1 simonbeck staff 0 Jun 8 09:21 . drwx------+ 6 simonbeck staff 192 Jun 8 09:15 .. dr-xr-xr-x 1 simonbeck staff 0 Jun 8 09:21 hosts dr-xr-xr-x 1 simonbeck staff 0 Jun 8 09:21 ids dr-xr-xr-x 1 simonbeck staff 0 Jun 8 09:21 snapshots dr-xr-xr-x 1 simonbeck staff 0 Jun 8 09:21 tags Here you can browse all backups by host, ids, snapshots or tags.","title":"Manual restore via Restic"}]}